{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bf06b0-f626-4a8a-ac31-de5fe73d11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"class_all_with_chronic_names.csv\")\n",
    "df = df[df['class'].isin([1, 2])]\n",
    "df['class'] = df['class'].map({1: 0, 2: 1})\n",
    "y = df['class']\n",
    "\n",
    "# Drop ID columns\n",
    "drop_cols = ['HASHED_PERSONID', 'ENCNTR_ID_SI', 'DIAG_DT_TM', 'ICD', 'DIAGNOSIS_DISPLAY', 'DIAG_TYPE']\n",
    "df.drop(columns=[col for col in drop_cols if col in df.columns], inplace=True)\n",
    "\n",
    "X = df.drop(columns=['class'])\n",
    "\n",
    "# Label encode\n",
    "for col in X.select_dtypes(include='object').columns:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
    "\n",
    "# Impute missing\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectKBest(score_func=f_classif, k=100)  # keep top 100 features\n",
    "X_selected = selector.fit_transform(X_poly, y)\n",
    "\n",
    "# Train/Validation/Test split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, stratify=y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Grid Search\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['elasticnet'],\n",
    "    'l1_ratio': [0.1, 0.5, 0.9],\n",
    "    'solver': ['saga'],  # saga supports elasticnet\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(\n",
    "    LogisticRegression(max_iter=5000),\n",
    "    param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_lr.fit(X_train_val, y_train_val)\n",
    "\n",
    "best_lr = grid_lr.best_estimator_\n",
    "print(\"üîç Best Parameters:\", grid_lr.best_params_)\n",
    "\n",
    "# Evaluate helper\n",
    "def evaluate(model, X, y, label):\n",
    "    y_pred = model.predict(X)\n",
    "    y_prob = model.predict_proba(X)[:, 1]\n",
    "    print(f\"\\nüìä {label} Set Classification Report:\")\n",
    "    print(classification_report(y, y_pred))\n",
    "    print(f\"‚úÖ Accuracy: {accuracy_score(y, y_pred):.4f}\")\n",
    "    print(f\"üéØ ROC-AUC: {roc_auc_score(y, y_prob):.4f}\")\n",
    "    return y, y_prob\n",
    "\n",
    "# Evaluate\n",
    "y_train_true, y_train_prob = evaluate(best_lr, X_train, y_train, \"Train\")\n",
    "y_val_true, y_val_prob = evaluate(best_lr, X_val, y_val, \"Validation\")\n",
    "y_test_true, y_test_prob = evaluate(best_lr, X_test, y_test, \"Test\")\n",
    "\n",
    "# Plot ROC Curve for Train, Validation, and Test sets\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Train\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train_true, y_train_prob)\n",
    "auc_train = roc_auc_score(y_train_true, y_train_prob)\n",
    "plt.plot(fpr_train, tpr_train, label=f\"Train AUC = {auc_train:.2f}\", linestyle='-')\n",
    "\n",
    "# Validation\n",
    "fpr_val, tpr_val, _ = roc_curve(y_val_true, y_val_prob)\n",
    "auc_val = roc_auc_score(y_val_true, y_val_prob)\n",
    "plt.plot(fpr_val, tpr_val, label=f\"Validation AUC = {auc_val:.2f}\", linestyle='--')\n",
    "\n",
    "# Test\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test_true, y_test_prob)\n",
    "auc_test = roc_auc_score(y_test_true, y_test_prob)\n",
    "plt.plot(fpr_test, tpr_test, label=f\"Test AUC = {auc_test:.2f}\", linestyle='-.')\n",
    "\n",
    "# Final plot settings\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Logistic Regression (Train, Val, Test)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
