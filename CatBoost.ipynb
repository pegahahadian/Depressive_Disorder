{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d48cc4e-0ba2-4ca3-aa28-41effdf7c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (\n",
    "    classification_report, accuracy_score, confusion_matrix,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# === Load and Prepare Dataset ===\n",
    "df = pd.read_csv(\"E:\\PXA252_BH\\OlderFiles20250512\\class_all_with_chronic_names.csv\")\n",
    "df = df[df['class'].isin([1, 2, 3])]\n",
    "df['class'] = df['class'].replace({1: 0, 2: 1, 3: 1})\n",
    "y = df['class']\n",
    "\n",
    "drop_cols = ['HASHED_PERSONID', 'ENCNTR_ID_SI', 'DIAG_DT_TM', 'ICD', 'DIAGNOSIS_DISPLAY', 'DIAG_TYPE']\n",
    "df.drop(columns=[col for col in drop_cols if col in df.columns], inplace=True)\n",
    "X = df.drop(columns=['class'])\n",
    "\n",
    "# Encode categorical columns\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "label_encoders = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Impute missing values\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X = pd.DataFrame(SimpleImputer(strategy=\"mean\").fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Feature selection using Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "top_features = pd.Series(rf.feature_importances_, index=X.columns).nlargest(30).index\n",
    "X = X[top_features]\n",
    "cat_cols = [col for col in cat_cols if col in X.columns]\n",
    "\n",
    "# === Stratified Train-Val-Test Split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# === Undersample Class 1 in Training ===\n",
    "rus = RandomUnderSampler(sampling_strategy=1.0, random_state=42)\n",
    "X_train_bal, y_train_bal = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Convert categorical columns to string\n",
    "for col in cat_cols:\n",
    "    X_train_bal[col] = X_train_bal[col].astype(str)\n",
    "    X_val[col] = X_val[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "cat_features = [X_train_bal.columns.get_loc(col) for col in cat_cols]\n",
    "\n",
    "# Compute class weights\n",
    "class_weights_values = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_bal), y=y_train_bal)\n",
    "class_weights = {i: w for i, w in enumerate(class_weights_values)}\n",
    "\n",
    "# === Train CatBoost Model with Regularization ===\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.03,\n",
    "    depth=5,\n",
    "    l2_leaf_reg=8,\n",
    "    eval_metric='F1',\n",
    "    random_seed=42,\n",
    "    cat_features=cat_features,\n",
    "    early_stopping_rounds=50,\n",
    "    class_weights={0: 1.1, 1: 1},\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(X_train_bal, y_train_bal, eval_set=(X_val, y_val), use_best_model=True)\n",
    "\n",
    "# === Evaluation Function ===\n",
    "def evaluate(model, X, y, label):\n",
    "    y_pred = model.predict(X)\n",
    "    y_prob = model.predict_proba(X)[:, 1]\n",
    "    print(f\"\\nðŸ“Š {label} Classification Report:\")\n",
    "    print(classification_report(y, y_pred))\n",
    "    print(f\"âœ… Accuracy: {accuracy_score(y, y_pred):.4f}\")\n",
    "    print(f\"ðŸŽ¯ ROC AUC: {roc_auc_score(y, y_prob):.4f}\")\n",
    "    return y, y_prob\n",
    "\n",
    "# Convert categorical features in all datasets to string before evaluation\n",
    "for col in cat_cols:\n",
    "    X_train[col] = X_train[col].astype(str)\n",
    "    X_val[col] = X_val[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "# Evaluate\n",
    "y_train_true, y_train_prob = evaluate(model, X_train, y_train, \"Train\")\n",
    "y_val_true, y_val_prob = evaluate(model, X_val, y_val, \"Validation\")\n",
    "y_test_true, y_test_prob = evaluate(model, X_test, y_test, \"Test\")\n",
    "\n",
    "# === Threshold Optimization (F1-Based) ===\n",
    "y_val_prob_inv = 1 - y_val_prob\n",
    "prec, rec, thresh = precision_recall_curve(y_val_true == 0, y_val_prob_inv)\n",
    "\n",
    "# Select threshold that maximizes class 0 recall, while keeping class 0 precision > 0.5\n",
    "best_thresh = 0.5\n",
    "max_recall = 0\n",
    "for p, r, t in zip(prec, rec, np.append(thresh, 1.0)):\n",
    "    if p > 0.5 and r > max_recall:\n",
    "        max_recall = r\n",
    "        best_thresh = 1 - t  # Invert back\n",
    "\n",
    "print(f\"ðŸ”§ Class 0 Recall-Optimized Threshold: {best_thresh:.3f}\")\n",
    "# === Evaluate on Test Set using this threshold\n",
    "y_test_pred_custom = (y_test_prob >= best_thresh).astype(int)\n",
    "\n",
    "print(\"\\nðŸ“Š Test Classification Report (Class 0 Recall-Based Threshold):\")\n",
    "print(classification_report(y_test_true, y_test_pred_custom))\n",
    "\n",
    "\n",
    "# === Evaluate on Test Set with Custom Threshold\n",
    "y_test_pred_custom = (y_test_prob > optimal_thresh).astype(int)\n",
    "print(\"\\nðŸ“Š Test Classification Report (Custom Threshold):\")\n",
    "print(classification_report(y_test_true, y_test_pred_custom))\n",
    "\n",
    "# === Confusion Matrix\n",
    "cm = confusion_matrix(y_test_true, y_test_pred_custom)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Class 0\", \"Class 1\"], yticklabels=[\"Class 0\", \"Class 1\"])\n",
    "plt.title(\"Confusion Matrix - Test (Custom Threshold)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "for y_true, y_prob, name in zip(\n",
    "    [y_train_true, y_val_true, y_test_true],\n",
    "    [y_train_prob, y_val_prob, y_test_prob],\n",
    "    ['Train', 'Validation', 'Test']\n",
    "):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} AUC = {auc:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves - CatBoost\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
