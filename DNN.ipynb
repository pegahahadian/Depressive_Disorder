{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5c3c42-7e5e-4c4d-a2e3-da391f9fc549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"class_all_with_chronic_names.csv\")\n",
    "df = df[df['class'].isin([1, 2])]\n",
    "df['class'] = df['class'].map({1: 0, 2: 1})\n",
    "y = df['class']\n",
    "\n",
    "# Drop irrelevant columns\n",
    "drop_cols = ['HASHED_PERSONID', 'ENCNTR_ID_SI', 'DIAG_DT_TM', 'ICD', 'DIAGNOSIS_DISPLAY', 'DIAG_TYPE']\n",
    "df.drop(columns=[col for col in drop_cols if col in df.columns], inplace=True)\n",
    "X = df.drop(columns=['class'])\n",
    "\n",
    "# Encode categorical features\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
    "\n",
    "# Impute missing and remove inf\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Select top 30 features using Random Forest\n",
    "rf_temp = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_temp.fit(X, y)\n",
    "top_30_features = pd.Series(rf_temp.feature_importances_, index=X.columns).sort_values(ascending=False).head(30).index.tolist()\n",
    "X = X[top_30_features]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Train/validation/test split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Define improved model\n",
    "def build_stronger_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=input_dim))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Build and train the model\n",
    "model = build_stronger_model(X_train.shape[1])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=10, verbose=1)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=32,\n",
    "                    class_weight=class_weights, callbacks=[early_stop, reduce_lr], verbose=1)\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_dnn(model, X, y, label):\n",
    "    prob = model.predict(X).flatten()\n",
    "    pred = (prob > 0.5).astype(int)\n",
    "    print(f\"\\nðŸ“Š {label} Classification Report:\")\n",
    "    print(classification_report(y, pred))\n",
    "    print(f\"âœ… Accuracy: {accuracy_score(y, pred):.4f}\")\n",
    "    print(f\"ðŸŽ¯ ROC-AUC: {roc_auc_score(y, prob):.4f}\")\n",
    "    return y, prob\n",
    "\n",
    "y_train_true, y_train_prob = evaluate_dnn(model, X_train, y_train, \"Train\")\n",
    "y_val_true, y_val_prob = evaluate_dnn(model, X_val, y_val, \"Validation\")\n",
    "y_test_true, y_test_prob = evaluate_dnn(model, X_test, y_test, \"Test\")\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for y_true, y_prob, label in zip(\n",
    "    [y_train_true, y_val_true, y_test_true],\n",
    "    [y_train_prob, y_val_prob, y_test_prob],\n",
    "    ['Train', 'Validation', 'Test']\n",
    "):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    plt.plot(fpr, tpr, label=f\"{label} AUC = {auc:.2f}\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.title(\"ROC Curves - Improved DNN\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix (test set)\n",
    "y_test_pred = (y_test_prob > 0.5).astype(int)\n",
    "cm = confusion_matrix(y_test_true, y_test_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Class 0\", \"Class 1\"], yticklabels=[\"Class 0\", \"Class 1\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix - Test Set (Improved DNN)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
